{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15acfeee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\where\\appdata\\roaming\\python\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\python313\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\where\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\where\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\where\\appdata\\roaming\\python\\python313\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\where\\appdata\\roaming\\python\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec820c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82b54211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject Id  Group Id  Age  Gender      Nationality  OMSI  Task1  Task2  \\\n",
      "0            1         1   27  Female            China   157      1      1   \n",
      "1            2         1   33    Male          British   893      1      1   \n",
      "2            3         1   25  Female           Polish   171      1      1   \n",
      "3            4         2   30    Male       Venezuelan   816      1      2   \n",
      "4            5         2   23    Male           Danish   132      1      2   \n",
      "5            6         2   25  Female  Danish/Egyptian   192      1      2   \n",
      "6            9         3   33  Female            Greek    96      1      1   \n",
      "7            8         3   33    Male   Northern irish    99      1      1   \n",
      "8            7         3   34    Male           Danish   454      1      1   \n",
      "9           10         4   24    Male           Danish    99      1      1   \n",
      "10          12         4   32    Male           Danish   367      1      1   \n",
      "11          11         4   25    Male         American   583      1      1   \n",
      "\n",
      "    Task3  Task4  ...  GQ2  GQ3  GQ4  GQ5  GQ6  GQ7  FQ1  FQ2  FQ3  \\\n",
      "0       1      3  ...    4    3    3    4    1    4    4    3    4   \n",
      "1       1      3  ...    1    1    1    5    3    5    4    4    5   \n",
      "2       1      3  ...    2    1    4    5    3    3    4    3    5   \n",
      "3       1      2  ...    2    1    1    5    3    4    1    3    5   \n",
      "4       1      2  ...    2    1    1    5    4    5    2    4    5   \n",
      "5       1      2  ...    5    1    1    5    4    5    3    5    5   \n",
      "6       1      3  ...    5    1    1    5    1    5    1    5    5   \n",
      "7       1      3  ...    3    1    1    5    3    5    2    1    5   \n",
      "8       1      3  ...    4    1    3    4    3    2    2    1    3   \n",
      "9       1      2  ...    4    1    2    4    1    2    3    4    4   \n",
      "10      1      2  ...    4    2    5    3    4    3    3    2    3   \n",
      "11      1      2  ...    1    1    1    4    4    5    1    4    2   \n",
      "\n",
      "                                             Comments  \n",
      "0                                                 NaN  \n",
      "1                                                  no  \n",
      "2                                                 NaN  \n",
      "3   Excellent idea. As a musician it was very intu...  \n",
      "4                                                 NaN  \n",
      "5   I love it!!!!!! Maybe for future, this could t...  \n",
      "6                                                 NaN  \n",
      "7   I would like the latency improved and a left h...  \n",
      "8                                                 NaN  \n",
      "9                                                 NaN  \n",
      "10                        through the fire and flames  \n",
      "11  If you can have the system a bit more responsi...  \n",
      "\n",
      "[12 rows x 34 columns]\n"
     ]
    }
   ],
   "source": [
    "# upload files\n",
    "csv_file_path = \"Aftertest _Questionnaire.csv\"\n",
    "data_afterquestionnaire = pd.read_csv(csv_file_path, usecols=[i for i in range(1,24)], header = 0, names = ['Subject Id', 'Group Id', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10','GQ1', 'GQ2', 'GQ3', 'GQ4', 'GQ5', 'GQ6', 'GQ7', 'FQ1', 'FQ2', 'FQ3', 'Comments'])\n",
    "data_afterquestionnaire.rename(columns={\"Subject Id\\n\":\"Subject Id\"}, inplace=True)\n",
    "\n",
    "data_afterquestionnaire.head()\n",
    "csv_file_path1 = \"Beforetest_Questionnaire.csv\"\n",
    "data_beforequestionnaire = pd.read_csv(csv_file_path1,usecols=[i for i in range(2,15)],header = 0, names=['Subject Id', 'Group Id', 'Age', 'Gender', 'Nationality', 'OMSI', 'Task1', 'Task2', 'Task3', 'Task4', 'Task5', 'Task6', 'Task7'])\n",
    "data_beforequestionnaire.loc[data_beforequestionnaire['Task5'] == 0, 'Task5'] = 6\n",
    "\n",
    "\n",
    "csv_file_path2 = \"AlternativeTestQuestionnaire.csv\"\n",
    "data_alternativequestionnaire = pd.read_csv(csv_file_path2,usecols=[i for i in range(1,17)],header = 0, names=['Subject Id', 'Group Id', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'FQ1', 'FQ2', 'FQ3', 'Comments'])\n",
    "data_alternativequestionnaire.head()\n",
    "\n",
    "csv_file_path2 = \"followup-test.csv\"\n",
    "data_followup = pd.read_csv(csv_file_path2,usecols=[i for i in range(0,8)],header = 0, names=['Subject Id','Task1', 'Task2', 'Task3', 'Task4', 'Task5', 'Task6', 'Task7'])\n",
    "data_followup.head()\n",
    "\n",
    "merged = data_beforequestionnaire.merge(data_afterquestionnaire, on=['Subject Id', 'Group Id'])\n",
    "\n",
    "print(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7da24b8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject Id    SUS  OMSI\n",
      "0            3   65.0   171\n",
      "1            1   45.0   157\n",
      "2            2   62.5   893\n",
      "3            5   77.5   132\n",
      "4            6   80.0   192\n",
      "5            4   92.5   816\n",
      "6            8   65.0    99\n",
      "7            9   97.5    96\n",
      "8            7   65.0   454\n",
      "9           10   55.0    99\n",
      "10          12   32.5   367\n",
      "11          11   47.5   583\n",
      "12          12   40.0   367\n",
      "13           5   92.5   132\n",
      "14           2   85.0   893\n",
      "15           4   90.0   816\n",
      "16          11   80.0   583\n",
      "17           8  100.0    99\n",
      "18           3   77.5   171\n",
      "19           7   80.0   454\n",
      "20          10   37.5    99\n",
      "21           6   90.0   192\n",
      "22           9   80.0    96\n",
      "Covariance between OMSI and SUS: 439.2687747035572\n",
      "Pearson correlation: 0.076\n",
      "P-value: 0.7296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Define question keys\n",
    "odd_questions = ['Q1', 'Q3', 'Q5', 'Q7', 'Q9']\n",
    "even_questions = ['Q2', 'Q4', 'Q6', 'Q8', 'Q10']\n",
    "\n",
    "# --- Process SUS_data ---\n",
    "SUS_data = data_afterquestionnaire[['Subject Id', 'Group Id'] + odd_questions + even_questions].copy()\n",
    "\n",
    "for q in odd_questions:\n",
    "    SUS_data[q] = SUS_data[q] - 1\n",
    "for q in even_questions:\n",
    "    SUS_data[q] = 5 - SUS_data[q]\n",
    "\n",
    "SUS_data['SUS'] = SUS_data[odd_questions + even_questions].sum(axis=1) * 2.5\n",
    "\n",
    "# --- Process SUS_data_alt ---\n",
    "SUS_data_alt = data_alternativequestionnaire[['Subject Id', 'Group Id'] + odd_questions + even_questions].copy()\n",
    "\n",
    "for q in odd_questions:\n",
    "    SUS_data_alt[q] = SUS_data_alt[q] - 1\n",
    "for q in even_questions:\n",
    "    SUS_data_alt[q] = 5 - SUS_data_alt[q]\n",
    "\n",
    "SUS_data_alt['SUS'] = SUS_data_alt[odd_questions + even_questions].sum(axis=1) * 2.5\n",
    "\n",
    "# --- Combine both SUS datasets ---\n",
    "combined_sus = pd.concat([SUS_data[['Subject Id', 'SUS']], SUS_data_alt[['Subject Id', 'SUS']]], ignore_index=True)\n",
    "\n",
    "# --- Get OMSI scores from before-questionnaire data ---\n",
    "omsi_data = data_beforequestionnaire[['Subject Id', 'OMSI']].copy()\n",
    "omsi_data['OMSI'] = pd.to_numeric(omsi_data['OMSI'], errors='coerce')\n",
    "\n",
    "# --- Merge on Subject Id ---\n",
    "merged_df = pd.merge(combined_sus, omsi_data, on='Subject Id')\n",
    "\n",
    "# Drop any missing values\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "# --- Run covariance test ---\n",
    "covariance = merged_df.cov().loc['OMSI', 'SUS']\n",
    "print(f\"Covariance between OMSI and SUS: {covariance}\")\n",
    "\n",
    "# --- Pearson correlation test ---\n",
    "corr, p_value = pearsonr(merged_df['OMSI'], merged_df['SUS'])\n",
    "print(f\"Pearson correlation: {corr:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# pearson cor = 0.076\n",
    "# p-value = 0.7296\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45268d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Subject Id    SUS  OMSI\n",
      "0            3   65.0   171\n",
      "1            1   45.0   157\n",
      "2            2   62.5   893\n",
      "3            5   77.5   132\n",
      "4            6   80.0   192\n",
      "5            4   92.5   816\n",
      "6            8   65.0    99\n",
      "7            9   97.5    96\n",
      "8            7   65.0   454\n",
      "9           10   55.0    99\n",
      "10          12   32.5   367\n",
      "11          11   47.5   583\n",
      "12          12   40.0   367\n",
      "13           5   92.5   132\n",
      "14           2   85.0   893\n",
      "15           4   90.0   816\n",
      "16          11   80.0   583\n",
      "17           8  100.0    99\n",
      "18           3   77.5   171\n",
      "19           7   80.0   454\n",
      "20          10   37.5    99\n",
      "21           6   90.0   192\n",
      "22           9   80.0    96\n",
      "Covariance between OMSI and SUS: 439.2687747035572\n",
      "Pearson correlation: 0.076\n",
      "P-value: 0.7296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Define question keys\n",
    "odd_questions = ['Q1', 'Q3', 'Q5', 'Q7', 'Q9']\n",
    "even_questions = ['Q2', 'Q4', 'Q6', 'Q8', 'Q10']\n",
    "\n",
    "# --- Process SUS_data ---\n",
    "SUS_data = data_afterquestionnaire[['Subject Id', 'Group Id'] + odd_questions + even_questions].copy()\n",
    "\n",
    "for q in odd_questions:\n",
    "    SUS_data[q] = SUS_data[q] - 1\n",
    "for q in even_questions:\n",
    "    SUS_data[q] = 5 - SUS_data[q]\n",
    "\n",
    "SUS_data['SUS'] = SUS_data[odd_questions + even_questions].sum(axis=1) * 2.5\n",
    "\n",
    "# --- Process SUS_data_alt ---\n",
    "SUS_data_alt = data_alternativequestionnaire[['Subject Id', 'Group Id'] + odd_questions + even_questions].copy()\n",
    "\n",
    "for q in odd_questions:\n",
    "    SUS_data_alt[q] = SUS_data_alt[q] - 1\n",
    "for q in even_questions:\n",
    "    SUS_data_alt[q] = 5 - SUS_data_alt[q]\n",
    "\n",
    "SUS_data_alt['SUS'] = SUS_data_alt[odd_questions + even_questions].sum(axis=1) * 2.5\n",
    "\n",
    "# --- Combine both SUS datasets ---\n",
    "combined_sus = pd.concat([SUS_data[['Subject Id', 'SUS']], SUS_data_alt[['Subject Id', 'SUS']]], ignore_index=True)\n",
    "\n",
    "# --- Get OMSI scores from before-questionnaire data ---\n",
    "omsi_data = data_beforequestionnaire[['Subject Id', 'OMSI']].copy()\n",
    "omsi_data['OMSI'] = pd.to_numeric(omsi_data['OMSI'], errors='coerce')\n",
    "\n",
    "# --- Merge on Subject Id ---\n",
    "merged_df = pd.merge(combined_sus, omsi_data, on='Subject Id')\n",
    "\n",
    "# Drop any missing values\n",
    "merged_df = merged_df.dropna()\n",
    "\n",
    "print(merged_df)\n",
    "\n",
    "# --- Run covariance test ---\n",
    "covariance = merged_df.cov().loc['OMSI', 'SUS']\n",
    "print(f\"Covariance between OMSI and SUS: {covariance}\")\n",
    "\n",
    "# --- Pearson correlation test ---\n",
    "corr, p_value = pearsonr(merged_df['OMSI'], merged_df['SUS'])\n",
    "print(f\"Pearson correlation: {corr:.3f}\")\n",
    "print(f\"P-value: {p_value:.4f}\")\n",
    "\n",
    "# pearson cor = 0.076\n",
    "# p-value = 0.7296\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
